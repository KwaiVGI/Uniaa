# Uniaa
<p align="center">
<img src="https://github.com/ZK-Zhou/spikformer/blob/main/images/spikformer-logo.png" width="20%">
</p>

# Spikformer: When Spiking Neural Network Meets Transformer, [ICLR 2023](https://openreview.net/forum?id=frE4fUwz_h).
# Spikformer V2: Join the High Accuracy Club on ImageNet with an SNN Ticket, [Arxiv](https://arxiv.org/abs/2401.02020).
The Spikformer V2 code will be released after it organized.
## Reference
If you find this repo useful, please consider citing:
```
@inproceedings{
zhou2023spikformer,
title={Spikformer: When Spiking Neural Network Meets Transformer },
author={Zhaokun Zhou and Yuesheng Zhu and Chao He and Yaowei Wang and Shuicheng YAN and Yonghong Tian and Li Yuan},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=frE4fUwz_h}
}
```
Our codes are based on the official imagenet example by PyTorch, pytorch-image-models by Ross Wightman and SpikingJelly by Wei Fang.

<p align="center">
<img src="https://github.com/ZK-Zhou/spikformer/blob/main/images/overview01.png">
</p>
